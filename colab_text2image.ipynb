{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvalsolaz/hanglider/blob/main/colab_text2image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9e9041",
      "metadata": {
        "id": "9f9e9041"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch as th\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def create_pil_image(batch: th.Tensor):\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    npimage = reshaped.numpy()\n",
        "    im = Image.fromarray(npimage)\n",
        "    return im.resize(size=(512,512))\n",
        "\n",
        "\n",
        "\n",
        "def image_show_pil(batch: th.Tensor, caption=''):\n",
        "    create_pil_image(batch).show(title=caption)"
      ],
      "metadata": {
        "id": "_tNRPx-zrYVB"
      },
      "id": "_tNRPx-zrYVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88696845",
      "metadata": {
        "id": "88696845"
      },
      "outputs": [],
      "source": [
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')\n",
        "print(f'using: {device} device\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ae48a1",
      "metadata": {
        "id": "b3ae48a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sampling parameters\n",
        "batch_size = 1\n",
        "guidance_scale = 3.0\n",
        "diffusion_steps = {'base': '100',       # use diffusion steps for fast sampling   in base model \n",
        "                   'upsample':'fast27'} # use upsample diffusion steps for very fast sampling in upsampling model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/glide-text2im"
      ],
      "metadata": {
        "id": "Pru8qLh4bRD7"
      },
      "id": "Pru8qLh4bRD7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf636cc",
      "metadata": {
        "id": "bbf636cc"
      },
      "outputs": [],
      "source": [
        "# Load / Create base model.\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import create_model_and_diffusion, model_and_diffusion_defaults\n",
        "\n",
        "print(f'use {diffusion_steps} diffusion steps for fast sampling')\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = diffusion_steps['base']  \n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "    model.to(device)\n",
        "    model.load_state_dict(load_checkpoint('base', device))\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aad6872",
      "metadata": {
        "id": "6aad6872"
      },
      "outputs": [],
      "source": [
        " # Load / Create upsampler model.\n",
        "from glide_text2im.model_creation import model_and_diffusion_defaults_upsampler\n",
        "\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "# options_up['timestep_respacing'] = diffusion_steps['upsample']\n",
        "\n",
        "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "model_up.eval()\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "    model_up.to(device)\n",
        "    model_up.load_state_dict(load_checkpoint('upsample', device))\n",
        "\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d05a55b",
      "metadata": {
        "id": "8d05a55b"
      },
      "outputs": [],
      "source": [
        "image_array = []\n",
        "def generate_image(prompt:str):\n",
        "    # Tune this parameter to control the sharpness of 256x256 images.\n",
        "    # A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "    upsample_temp = 0.997\n",
        "\n",
        "    # Create a classifier-free guidance sampling function\n",
        "    def model_fn(x_t, ts, **kwargs):\n",
        "        half = x_t[: len(x_t) // 2]\n",
        "        combined = th.cat([half, half], dim=0)\n",
        "        model_out = model(combined, ts, **kwargs)\n",
        "        eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "        cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "        half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "        eps = th.cat([half_eps, half_eps], dim=0)\n",
        "        image = th.cat([eps, rest], dim=1)\n",
        "        # image_show_pygame(eps, caption=f'frame #{N}')\n",
        "        # image_show_pygame(rest, caption=f'shape {rest.shape}')\n",
        "        image_array.append(create_pil_image(rest))\n",
        "        \n",
        "        return image\n",
        "\n",
        "    ##############################\n",
        "    # Sample from the base model #\n",
        "    ##############################\n",
        "\n",
        "    # Create the text tokens to feed to the model.\n",
        "    tokens = model.tokenizer.encode(prompt)\n",
        "    tokens, mask = model.tokenizer.padded_tokens_and_mask(tokens, options['text_ctx'])\n",
        "\n",
        "    # Create the classifier-free guidance tokens (empty)\n",
        "    full_batch_size = batch_size * 2\n",
        "    uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask([], options['text_ctx'])\n",
        "\n",
        "    # Pack the tokens together into model kwargs.\n",
        "    model_kwargs = dict(\n",
        "        tokens=th.tensor(\n",
        "            [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
        "        ),\n",
        "        mask=th.tensor(\n",
        "            [mask] * batch_size + [uncond_mask] * batch_size,\n",
        "            dtype=th.bool,\n",
        "            device=device,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # Sample from the base model.\n",
        "    model.del_cache()\n",
        "    samples = diffusion.p_sample_loop(\n",
        "        model_fn,\n",
        "        (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "        device=device,\n",
        "        clip_denoised=True,\n",
        "        progress=True,\n",
        "        model_kwargs=model_kwargs,\n",
        "        cond_fn=None,\n",
        "    )[:batch_size]\n",
        "    model.del_cache()\n",
        "    return samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2958d20d",
      "metadata": {
        "id": "2958d20d"
      },
      "source": [
        "#### enter image caption for image generation: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230eb255",
      "metadata": {
        "id": "230eb255"
      },
      "outputs": [],
      "source": [
        "!jupyter nbextension enable --py widgetsnbextension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20554632",
      "metadata": {
        "id": "20554632"
      },
      "outputs": [],
      "source": [
        "#import ipywidgets as widgets\n",
        "#from IPython.display import display\n",
        "# dir(widgets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipyplot\n",
        "import ipyplot"
      ],
      "metadata": {
        "id": "eoADXzsQ8e1O"
      },
      "id": "eoADXzsQ8e1O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8c4c8b",
      "metadata": {
        "id": "ba8c4c8b"
      },
      "outputs": [],
      "source": [
        "image_array = []\n",
        "prompt = input('enter image caption for image generation: ')\n",
        "print (f'generating image for: {prompt}')\n",
        "images = []\n",
        "for i in range(3):\n",
        "    samples = generate_image(prompt=prompt)\n",
        "    # Show the output\n",
        "    image_show_pil(samples, caption=prompt)\n",
        "    images.append(create_pil_image(samples))\n",
        "ipyplot.plot_images(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baa50769",
      "metadata": {
        "id": "baa50769"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Copy of text2image.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}